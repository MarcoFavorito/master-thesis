


@article{Brafman2017SpecifyingNR,
	title={Specifying Non-Markovian Rewards in MDPs Using LDL on Finite Traces (Preliminary Version)},
	author={Ronen I. Brafman and Giuseppe De Giacomo and Fabio Patrizi},
	journal={CoRR},
	year={2017},
	volume={abs/1706.08100}
}





% REINFOCEMENT LEARNING
@book{Sutton:1998:IRL:551283,
	author = {Sutton, Richard S. and Barto, Andrew G.},
	title = {Introduction to Reinforcement Learning},
	year = {1998},
	isbn = {0262193981},
	edition = {1st},
	publisher = {MIT Press},
	address = {Cambridge, MA, USA},
}

@inproceedings{Ng:1999:PIU:645528.657613,
	author = {Ng, Andrew Y. and Harada, Daishi and Russell, Stuart J.},
	title = {Policy Invariance Under Reward Transformations: Theory and Application to Reward Shaping},
	booktitle = {Proceedings of the Sixteenth International Conference on Machine Learning},
	series = {ICML '99},
	year = {1999},
	isbn = {1-55860-612-2},
	pages = {278--287},
	numpages = {10},
	url = {http://dl.acm.org/citation.cfm?id=645528.657613},
	acmid = {657613},
	publisher = {Morgan Kaufmann Publishers Inc.},
	address = {San Francisco, CA, USA},
}

@inproceedings{Grzes:2017:RSE:3091125.3091208,
	author = {Grze\'{s}, Marek},
	title = {Reward Shaping in Episodic Reinforcement Learning},
	booktitle = {Proceedings of the 16th Conference on Autonomous Agents and MultiAgent Systems},
	series = {AAMAS '17},
	year = {2017},
	location = {S\&\#227;o Paulo, Brazil},
	pages = {565--573},
	numpages = {9},
	url = {http://dl.acm.org/citation.cfm?id=3091125.3091208},
	acmid = {3091208},
	publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
	address = {Richland, SC},
	keywords = {multiagent learning, potential-based reward shaping, reinforcement learning, reward shaping, reward structures for learning},
} 


@inproceedings{Devlin:2012:DPR:2343576.2343638,
	author = {Devlin, Sam and Kudenko, Daniel},
	title = {Dynamic Potential-based Reward Shaping},
	booktitle = {Proceedings of the 11th International Conference on Autonomous Agents and Multiagent Systems - Volume 1},
	series = {AAMAS '12},
	year = {2012},
	isbn = {0-9817381-1-7, 978-0-9817381-1-6},
	location = {Valencia, Spain},
	pages = {433--440},
	numpages = {8},
	url = {http://dl.acm.org/citation.cfm?id=2343576.2343638},
	acmid = {2343638},
	publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
	address = {Richland, SC},
	keywords = {reinforcement learning, reward shaping},
}

@phdthesis{grzes2010improving,
	title={Improving exploration in reinforcement learning through domain knowledge and parameter analysis},
	author={Grzes, Marek},
	year={2010},
	school={University of York}
}

@inproceedings{GuptaPerformanceCO,
	title={Performance Comparison of Sarsa(λ) and Watkin’s Q(λ) Algorithms},
	author={Karan M. Gupta}
}

@inproceedings{NMRDP DBLP:conf/aaai/BacchusBG96,
	author    = {Fahiem Bacchus and Craig Boutilier and Adam J. Grove},
	title     = {Rewarding Behaviors},
	booktitle = {AAAI/IAAI, Vol. 2},
	pages     = {1160--1167},
	publisher = {{AAAI} Press / The {MIT} Press},
	year      = {1996}
}

% LOGIC

@inproceedings{Pnueli:1977:TLP:1382431.1382534,
	author = {Pnueli, Amir},
	title = {The Temporal Logic of Programs},
	booktitle = {Proceedings of the 18th Annual Symposium on Foundations of Computer Science},
	series = {SFCS '77},
	year = {1977},
	pages = {46--57},
	numpages = {12},
	url = {https://doi.org/10.1109/SFCS.1977.32},
	doi = {10.1109/SFCS.1977.32},
	acmid = {1382534},
	publisher = {IEEE Computer Society},
	address = {Washington, DC, USA},
}

@inproceedings{de2013linear,
	title={Linear Temporal Logic and Linear Dynamic Logic on Finite Traces.},
	author={De Giacomo, Giuseppe and Vardi, Moshe Y},
	booktitle={IJCAI},
	volume={13},
	pages={854--860},
	year={2013}
}
